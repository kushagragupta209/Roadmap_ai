maiper â€” ReAct-based Agentic LLM Pipeline using Groq LLaMA

maiper is an agentic AI project that uses the ReAct (Reason + Act) prompting framework with Groqâ€™s ultra-fast LLaMA models to build structured, tool-using AI workflows.
This project demonstrates how to generate structured outputs such as roadmaps, JSON results, and agent-driven reasoning using custom prompts.

â¸»

ğŸš€ Features

âœ… ReAct-Style AI Agent
	â€¢	Implements the ReAct (Think â†’ Act â†’ Observe â†’ Answer) pattern.
	â€¢	Uses a custom prompt from reAct_prompt/reAct.py.

âš¡ Groq LLaMA Integration
	â€¢	Calls meta-llama/llama-4-maverick-17b-128e-instruct through Groq API.
	â€¢	Extremely low latency and high-throughput inference.

ğŸ“¦ Structured Output Handling
	â€¢	Extracts pure JSON from messy model outputs.
	â€¢	Parses roadmaps, mermaid diagrams, lists, and nested structures.

ğŸ§ª Custom Query Pipeline
	â€¢	Example prompt: â€œGive me the roadmap for GATE 2026 DA exam.â€
	â€¢	Automatically returns structured study plans.

ğŸ“Œ Future Improvements
	â€¢	Add Streamlit UI for roadmap visualization
	â€¢	Add multiple agents (search agent, reasoning agent)
	â€¢	Add proper tool-use execution engine
	â€¢	Add CLI runner

â¸»

ğŸ¤ Contributing

Contributions and pull requests are welcome!
Feel free to open issues for bugs, discussions, or feature requests.
